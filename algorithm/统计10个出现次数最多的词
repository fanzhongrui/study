一个文本文件有上亿行甚至10亿行，每行中存放一个词，要求统计其中出现次数最多的前10个词。

解法一：
    如果文件比较大，无法一次性读入内存，可以采用散列取模的方法，
    将大文件分解为多个小文件，对单个小文件利用hash_map统计出每个小文件中10个出现次数最多的词，
    然后再进行归并处理，找出最终的10个出现次数最多的词。

解法二：
    通过散列取模将大文件分解为多个小文件后，除了可以用hash_map统计出每个小文件中10个出现次数的词，
    也可以用Trie树统计每个词出现的次数，最终同样找出出现次数最多的前10个词（可用堆来实现）。
