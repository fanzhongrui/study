两个线程需要同时访问一个中间临界区（Queue），比如常会用缓存作为外部文件的副本（HashMap）。
三种并发集合类型有concurrent，copyonright，queue。
本文介绍ConcurrentHashMap。

通过分析Hashtable知道，synchronized是针对整张Hash表的，即每次锁住整张表让线程独占，
ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术。
它使用了多个锁来控制对hash表的不同部分进行的修改。
ConcurrentHashMap内部使用段（Segment）来表示这些不同的部分，每个段其实就是一个小的hash table，它们有自己的锁。
只要多个修改操作发生在不同的段上，它们就可以并发进行。
有些方法需要跨段，比如size（）和containsValue（），它们可能需要锁定整个表而不仅仅是某个段，
  这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁。
这里“按顺序”很重要，否则极有可能出现死锁，在ConcurrentHashMap内部，段数组是final的，并且其成员变量实际上也是final的，
  但是，仅仅是将数组声明为final的并不保证数组成员也是final的，需要实现上的保证。
由于获得锁的顺序是固定的，这可以确保不会出现死锁。

一、结构解析
  ConcurrentHashMap和Hashtable主要区别是围绕着锁的粒度以及如何锁。
  ConcurrentHashMap可以简单理解为把一个大的Hashtable分解成多个，形成了锁分离。
  而Hashtable的实现方式是——锁整个hash表
  
二、应用场景
  当有一个大数组时需要在多个线程共享时就可以考虑是否把它给分成多个节点了，避免大锁。
  并可以考虑通过hash算法进行一些模块定位。
  
  其实不止用于线程，当设计数据表的事务时（事务某种意义上也是同步机制的体现），可以把一个表看成一个需要同步的数组，
    如果操作的表数据太多时就可以考虑事务分离了（这也是为什么要避免大表的出现），比如把数据进行字段拆分，水平分表等
    
三、源码解读
  ConcurrentHashMap中主要实体类有三个：ConcurrentHashMap（整个Hash表），Segment（桶），HashEntry（节点）
      final Segment<K, V>[] segments;  //the segments, each of which is a specialized hash table
  
  不变（Immutable）和易变（Volatile）
  ConcurrentHashMap完全允许多个读操作并发进行，读操作并不需要加锁。如果使用传统的技术，
  如HashMap中的实现，如果允许可以在hash链的中间添加或删除元素，读操作不加锁将得到不一致的数据。
  ConcurrentHashMap实现技术是保证HashEntry几乎是不可变的。
  HashEntry代表每个hash链中的一个节点，其结构如下：
      static final class HashEntry<K,V>{
          final K key;
          final int hash;
          volatile V value;
          final HashEntry<K,V> next;
      }
  可以看到除了value不是final的，其它值都是final的，这意味着不能从hash链的中间或尾部添加或删除节点，因为这需要修改next引用值，
    所有节点的修改只能从头部开始。
  对于put操作，可以一律添加到Hash链的头部。但是对于remove操作，可能需要从中间删除一个节点，
      这就需要将要删除节点的前面所有节点整个复制一遍，最后一个节点指向要删除节点的下一个节点。
  为了确保读操作能够看到最新的值，将value设置成volatile，这避免了加锁。
  
其它
    为了加快定位段以及段中hash槽的速度，每个段hash槽的个数都是2^n,这使得通过位运算就可以定位段和段中hash槽的位置。
    当并发级别为默认值16时，即段的个数，hash值的高4位决定分配在哪个段中。
    注意：hash槽的个数不应该是2^n，这可能导致hash槽分配不均，这需要对hash值重新再hash一次。
      定位段的方法：
      final Segment<K,V> segmentFor(int hash){
          return segments[(hash >>> segmentShift) & segmentMask];
      }
    
  数据结构
      Hash表的一个很重要方面就是如何解决hash冲突，ConcurrentHashMap和HashMap使用相同的方式，，都是将hash值相同的节点放在一个hash链中。
      与HashMap不同的是，ConcurrentHashMap使用多个子Hash表，也就是段（Segment）。
      ConcurrentHashMap的数据成员：
        public class ConcurrentHashMap<K,V> extends AbstractMap<K,V>
            implements ConcurrentMap<K,V>,Serializable{
            /*Mask value for indexing into segments.
             *The upper bits of a key's hash code are used to choose the segment
             */
            final int segmentMask;
            /*Shift value for indexing within segments.
             */
            final int segmentShift;
             /*The segments, each of which is a specialized hash table
             */
            final Segment<K,V>[] segments;
        }
      所有的成员都是final的，其中segmentMask和segmentShift主要是为了定位段，参见segmentFor方法。
      每个Segment相当于一个子Hash表，它的数据成员如下：
        static final class Segment<K,V> extends ReentrantLock implements Serializable{
            private static final long serialVersionUID = 2249069246763182397L;  
            transient volatile int count;
            transient int modCount;
            transient int threshold;
            transient volatile HashEntry<K,V>[] table;
            final float loadFactor;
        }
      count用来统计该段数据的个数，它是volatile，它用来协调修改和读取操作，以保证读取操作能够读取到几乎最新的修改。
      协调方式如下：每次修改操作做了结构上的改变，如增加／删除节点（修改节点的值不算结构上的改变），都要写count值，每次读取操作开始都要读取count的值。
      这利用了java 5中对volatile语义的增强，对同一个volatile变量的写和读存在happens－before关系。
      modCount统计段结构改变的次数，主要是为了检测对多个段进行遍历过程中某个段是否发生改变。
      
      threshold用来表示需要进行rehash的界限值。
      table数组存储段中节点，每个数组元素是个hash链，用HashEntry表示。
      table也是volatile，这使得能够读取到最新的table值而不需要同步。
      loadFactor表示负载因子。
      
    删除
      public V remove(Object key){
          hash = hash(key.hashCode());
          return segmentFor(hash).remove(key, hash, null);
      }
      整个操作是先定位到段，然后委托给段的remove操作。当多个删除操作并发进行时，只要它们所在的段不相同，它们就可以同时进行。
      下面是segment的remove方法实现：
      V remove(Object key, int hash, Object value){
          lock();
          try{
              int c = count - 1;
              HashEntry<K,V>[] tab = table;
              int index = hash & (tab.length - 1);
              HashEntry<K,V> first = tab[index];
              HashEntry<K,V> e = first;
              
      }
      整个操作是在持有段锁的情况下执行的，空白行之前的行主要是定位到要删除的节点e。
      然后，如果不存在这个节点就直接返回null，否则就要将e前面的节点复制一遍，尾节点指向e的下一个节点。
      e后面的节点不需要复制，它们可以重用。
      从代码来看，中间那个for循环是将定位之后的所有entry克隆并拼回前面去。
      每次删除一个元素就要将那之前的元素克隆一遍，这点其实是由entry的不变性来决定的。
      entry定义中，除了value，其他所有属性都是用final来修饰的，这意味着在第一次设置了next域之后便不能再改变它，取而代之的是将它之前的节点全都克隆一次。
      至于entry为什么要设置不变性，这跟不变性的访问不需要同步从而节省时间有关。
      
      整个remove实现并不复杂，但是需要注意以下几点：
          第一，当要删除的节点存在时，删除的最后一步操作要将count的值减一。这必须是最后一步操作，否则读取操作可能看不到之前对段所做的结构性修改。
          第二，remove执行的开始就将table赋给一个局部变量tab，因为table是volatile变量，读写volatile变量的开销很大。
              编译也不能对volatile变量的读写做任何优化，直接多次访问非volatile实例变量没有多大影响，编译器会做相应优化。
      
    同样，put操作也是委托给段的put方法。
      
      
      
      
      
      
      
      
