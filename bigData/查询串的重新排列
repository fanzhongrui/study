  有10个文件，每个文件的大小是1GB，每个文件的每一行存放的都是用户的查询串query，
  每个文件的query都可能重复。请按照query的频度排序。
  
  解法一：
      分为三个步骤：
      1.散列映射。
          顺序读取10个文件，按照hash(query)%10的结果将query写入另外10个文件（记为a0,a1,...,a9）中。
          这样，新生成的每个文件的大小约为1GB（假设散列函数是随机的）。
          （如果散列函数可能会导致文件不均匀，所以可以先遍历一遍所有文件，每次读满内存后立刻写回文件，
            统计文件数目n，hash(query)%n）
      2.hash_map统计。
          找一台内存在2GB左右的机器，依次用hash_map(query,query_count)来统计每个query出现的次数。
          注意，hash_map(query, query_count)是用来统计每个query的出现次数的，而不是存储它们的值，query出现一次则query_count+1.
      3.堆排序、快速排序或者归并排序。
          利用快速排序、堆排序或者归并排序按照出现次数进行排序，将排好序的query和对应的query_count输出到文件中。
          这样就得到了10个排好序的文件（记为b0,b1,...,b9）。最后，对这10个文件进行归并排序
          （内排与外排相结合）。
      
  解法二：
      一般情况下，query的总量是有限的，只是重复的次数比较多而已，对于所有的query，可能一次性就可以加入内存。
      这样就可以采用Trie树、hash_map等直接统计每个query出现的次数，
      然后按出现次数做快速排序、堆排序或者归并排序就可以了
      
  解法三：
      与解法一类似，但在做完散列，分成多个文件后，可以交给多个文件，采用分布式架构来处理
      （如MapReduce），最后再进行合并。
